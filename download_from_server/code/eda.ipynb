{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files are 156\n"
     ]
    }
   ],
   "source": [
    "df_lists = sorted(glob.glob('../data/*.csv'))\n",
    "print(f'all files are {len(df_lists)}')\n",
    "df = None\n",
    "for df_path in df_lists:\n",
    "    if df is None:\n",
    "        df = pd.read_csv(df_path)\n",
    "    else:\n",
    "        tmp = pd.read_csv(df_path)\n",
    "        df = pd.concat([df,tmp])\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../full_list.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "1     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "2     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "3     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "4     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "5     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "6     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "7     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "8     6.9 ThorAbd Liver Dynamic 3phase+Thorax\n",
       "9                              5.10 ThorPel P\n",
       "10                             5.10 ThorPel P\n",
       "11                             5.10 ThorPel P\n",
       "12                                  胸部　単純　SHR\n",
       "13                                  胸部　単純　SHR\n",
       "14                                  胸部　単純　SHR\n",
       "15          ['胸部〜骨盤　膵ダイナミック3\u001b$BAj!', '(頸)胸部']\n",
       "16          ['胸部〜骨盤　膵ダイナミック3\u001b$BAj!', '(頸)胸部']\n",
       "17          ['胸部〜骨盤　膵ダイナミック3\u001b$BAj!', '(頸)胸部']\n",
       "18          ['胸部〜骨盤　膵ダイナミック3\u001b$BAj!', '(頸)胸部']\n",
       "19          ['胸部〜骨盤　膵ダイナミック3\u001b$BAj!', '(頸)胸部']\n",
       "Name:  protocol_name, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' protocol_name'].head(20)#.fillna('nan').str.lower().str.contains('|'.join(searchfor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218034, 18)\n",
      "(93131, 18)\n",
      "(59128, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52231/52231 [03:47<00:00, 229.75it/s]\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame([])\n",
    "\n",
    "df['ID'] = df['Facility_Code']+df[' Accesion_Number']\n",
    "ids = df['ID'].unique()\n",
    "##腹部以外のprotocol を排除\n",
    "searchfor = ['abd','pancreas','liver','pk','pel','renal','kub','colon','骨盤','腹','体幹']\n",
    "print(df.shape)\n",
    "df = df[df[' protocol_name'].fillna('nan').str.lower().str.contains('|'.join(searchfor))]\n",
    "print(df.shape)\n",
    "\n",
    "df = df[df[' image_type'].str.lower().str.contains('axial')]\n",
    "print(df.shape)\n",
    "###スライス少ないのはスカウト等なので排除\n",
    "###window_centerがマイナスなのは肺野なので排除。それと一緒に取っている同じスライス数の画像もおそらく胸部の縦隔条件なので排除。\n",
    "\n",
    "for id in tqdm(ids):\n",
    "    tmp = df[df['ID'] == id].reset_index(drop=True)\n",
    "    num_slices = tmp[' Number_of_Slices']\n",
    "    window_isminus = tmp[' window_center'].str.contains('-')\n",
    "    num_slices_low = num_slices<40\n",
    "    lung_slices = num_slices[window_isminus]\n",
    "    lung_slices = np.isin(num_slices,lung_slices)\n",
    "\n",
    "    exclude_slices = num_slices_low | lung_slices\n",
    "    \n",
    "\n",
    "    tmp = tmp[~exclude_slices].reset_index(drop=True)\n",
    "\n",
    "    new_df = pd.concat([new_df,tmp])\n",
    "\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "new_df['path'] = new_df['Facility_Code'].astype('str')+'_'+new_df[' Accesion_Number'].astype('int').astype('str')+\\\n",
    "    '_'+new_df[' Series_Number'].fillna(9999).astype('int').astype('str').str.zfill(4)+'_'+new_df[' Number_of_Slices'].astype(int).astype('str').str.zfill(3)+'.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df.to_csv('../include_abdomen.csv',index=False,encoding='utf_8_sig')\n",
    "new_df['path'].to_csv('../include_abdomen_path.csv',index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43157400144_1776520420220118_0009_420.nii.gz      4\n",
       "43157400144_1776520420220118_0007_420.nii.gz      4\n",
       "43157400144_1776520420220118_0010_420.nii.gz      4\n",
       "17035395872_1210200375998535_0301_5824.nii.gz     4\n",
       "17035395872_1210200375998535_0302_16768.nii.gz    4\n",
       "                                                 ..\n",
       "17144592271_4590839120220122_0002_138.nii.gz      1\n",
       "17144592271_4603555320220127_0002_057.nii.gz      1\n",
       "17144592271_4604165520220127_0002_050.nii.gz      1\n",
       "17144592271_4604165520220127_0003_043.nii.gz      1\n",
       "118_6010018780460_0201_158.nii.gz                 1\n",
       "Name: path, Length: 41190, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['path'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../rename.csv')\n",
    "new_df = new_df.merge(df,how='left',right_on='original_name',left_on='path')#.to_csv('rename.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50 2741\n",
      "50 100 17843\n",
      "100 150 15994\n",
      "150 200 5494\n",
      "200 250 356\n",
      "250 300 168\n",
      "300 350 139\n",
      "350 400 26\n",
      "400 450 28\n"
     ]
    }
   ],
   "source": [
    "sm = 0\n",
    "for i in np.arange(0,450,50):\n",
    "    tmp = new_df[(new_df[' Number_of_Slices']>=i) & (new_df[' Number_of_Slices']<i+50)]\n",
    "    print(i,i+50,len(tmp))\n",
    "    sm += len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
       "       275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
       "       288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
       "       301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
       "       314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
       "       327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
       "       340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
       "       353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "       366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "       379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "       392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
       "       405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
       "       418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
       "       431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,\n",
       "       444, 445, 446, 447, 448, 449])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(15,450,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42789"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###スライス数ごとに画像を分けて、別々のフォルダに保存する\n",
    "###フォルダ内のファイル数を一定に保つ\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='In order to remove unnecessary background, crop images based on segmenation labels.')\n",
    "    parser.add_argument('--datadir', default=\"../data/abd_20220101-20220605/\",\n",
    "                        help='dafault data directory')\n",
    "    parser.add_argument('--start_id', default=0, type=int,\n",
    "                        help='a number to start rename , (default: 0)')\n",
    "    parser.add_argument('--num_threads', default=20, type=int,\n",
    "                        help='number of threds to process , (default: 20)')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    datadir = args.datadir\n",
    "    start_id = args.start_id\n",
    "\n",
    "    img_paths = sorted(glob.glob(os.path.join(datadir,'*.nii.gz')))\n",
    "    print(len(img_paths))\n",
    "    num_imgs = len(img_paths)\n",
    "    num_slices = [int(i.split('_')[-1].split('.')[0]) for i in img_paths]\n",
    "\n",
    "    new_paths = [f'jmid_{str(i+start_id).zfill(7)}_0000.nii.gz' for i in range(num_imgs)]\n",
    "    img_paths_base = [os.path.basename(p) for p in img_paths]\n",
    "\n",
    "    df = pd.DataFrame([img_paths_base,new_paths]).T\n",
    "    df.columns = ['original_name','renamed']\n",
    "    df.to_csv('rename_20211001-20211231.csv',index=False)\n",
    "\n",
    "    dir_id = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        os.makedirs(f'../data1/remain_{str(i)}_0',exist_ok=True)\n",
    "\n",
    "    for num_slice,img_path,new_path in tqdm(zip(num_slices,img_paths,new_paths)):\n",
    "        if num_slice>=450:continue\n",
    "        else:\n",
    "            out_dir = '../data1/remain_' + str(8-i//50) + '_0'\n",
    "            shutil.copyfile(img_path,os.path.join(out_dir,new_path))\n",
    "    print('data copied!')\n",
    "    ####\n",
    "    ####8,7→5000 6→2000, 5→1000 4→700 3→400 2→300 1,0→100\n",
    "    for i in range(9):\n",
    "        if i == 8 or i == 7:\n",
    "            upper = 5000\n",
    "        elif i == 6:\n",
    "            upper = 2000\n",
    "        elif i == 5:\n",
    "            upper = 1000\n",
    "        elif i == 4:\n",
    "            upper = 700\n",
    "        elif i == 3:\n",
    "            upper = 400\n",
    "        elif i == 2:\n",
    "            upper = 300\n",
    "        else:\n",
    "            upper = 100\n",
    "\n",
    "\n",
    "        files = glob.glob(f'../data1/remain_{str(i)}_0/*nii.gz')\n",
    "        num_files = len(files)\n",
    "        num_folder = num_files//upper\n",
    "        for n in range(num_folder):\n",
    "            os.makedirs(f'../data1/remain_{str(i)}_{str(n+1)}',exist_ok=True)\n",
    "        for k,path in enumerate(files):\n",
    "            dir_id = k // upper\n",
    "            if dir_id >= 1:\n",
    "                shutil.move(path,os.path.join(f'../data1/remain_{str(i)}_{str(dir_id)}',os.path.basename(path)))\n",
    "    print('file moved.')\n",
    "\n",
    "##########################################3333\n",
    "\n",
    "df = pd.read_csv('merged_rename.csv')\n",
    "df.drop_duplicates(subset='renamed', keep='last', inplace=True)\n",
    "remain_paths = glob.glob('../data/remain_img/*.nii.gz')\n",
    "remain_base_paths = [os.path.basename(p) for p in remain_paths]\n",
    "num_processed_imgs = 0\n",
    "num_dir = 0\n",
    "\n",
    "for i in range(9):\n",
    "    os.makedirs(f'../data/remain_{str(i)}_0',exist_ok=True)\n",
    "\n",
    "for i in np.arange(0,450,50):\n",
    "    print(i)\n",
    "    tmp = df[(df[' Number_of_Slices']>=i) & (df[' Number_of_Slices']<i+50)]\n",
    "    for n,name in tqdm(enumerate(tmp['renamed'])):\n",
    "        if name in remain_base_paths:\n",
    "            num_processed_imgs+=1\n",
    "            dirsize = str(9-i//50)\n",
    "            out_dir = '../data/remain_'+dirsize+str(num_dir)\n",
    "            shutil.copyfile(f'../data/remain_img/{name}',out_dir)\n",
    "        if len(os.listdir(out_dir))>=2000:\n",
    "            num_dir+=1\n",
    "            os.makedirs(f'../data/remain_{dirsize}_{num_dir}',exist_ok=True)\n",
    "    num_dir = 0\n",
    "\n",
    "print(num_processed_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facility_Code</th>\n",
       "      <th>Accesion_Number</th>\n",
       "      <th>Series_Number</th>\n",
       "      <th>Number_of_Slices</th>\n",
       "      <th>modality</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>patient_sex</th>\n",
       "      <th>patient_age</th>\n",
       "      <th>contrast_bolus_agent</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>conv_kernel</th>\n",
       "      <th>window_center</th>\n",
       "      <th>window_width</th>\n",
       "      <th>patient_orientation</th>\n",
       "      <th>image_type</th>\n",
       "      <th>protocol_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>path</th>\n",
       "      <th>path_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43157400144</td>\n",
       "      <td>1148655720201211.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>074Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>Discovery CT750 HD</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>35</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>6.9 ThorAbd Liver Dynamic 3phase+Thorax</td>\n",
       "      <td>1148698877601355.0</td>\n",
       "      <td>43157400144_1148655720201211_0002_053.nii.gz</td>\n",
       "      <td>43157400144_1148655720201211_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43157400144</td>\n",
       "      <td>1148655720201211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>074Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>Discovery CT750 HD</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>55</td>\n",
       "      <td>320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>6.9 ThorAbd Liver Dynamic 3phase+Thorax</td>\n",
       "      <td>1148698877601355.0</td>\n",
       "      <td>43157400144_1148655720201211_0003_053.nii.gz</td>\n",
       "      <td>43157400144_1148655720201211_0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43157400144</td>\n",
       "      <td>1148655720201211.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>074Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>Discovery CT750 HD</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>55</td>\n",
       "      <td>320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>6.9 ThorAbd Liver Dynamic 3phase+Thorax</td>\n",
       "      <td>1148698877601355.0</td>\n",
       "      <td>43157400144_1148655720201211_0004_053.nii.gz</td>\n",
       "      <td>43157400144_1148655720201211_0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43157400144</td>\n",
       "      <td>1148655720201211.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>074Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>Discovery CT750 HD</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>55</td>\n",
       "      <td>320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>6.9 ThorAbd Liver Dynamic 3phase+Thorax</td>\n",
       "      <td>1148698877601355.0</td>\n",
       "      <td>43157400144_1148655720201211_0005_053.nii.gz</td>\n",
       "      <td>43157400144_1148655720201211_0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43157400144</td>\n",
       "      <td>1167702520201223.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>072Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>Discovery CT750 HD</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>5.10 ThorPel P</td>\n",
       "      <td>1167745677601367.0</td>\n",
       "      <td>43157400144_1167702520201223_0002_131.nii.gz</td>\n",
       "      <td>43157400144_1167702520201223_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42819</th>\n",
       "      <td>118</td>\n",
       "      <td>6010016870769.0</td>\n",
       "      <td>201</td>\n",
       "      <td>131</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>034Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips</td>\n",
       "      <td>iCT 256</td>\n",
       "      <td>B</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>[340, 340]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>Chest-Pelivis /iCT in HU</td>\n",
       "      <td>6010016870887.0</td>\n",
       "      <td>118_6010016870769_0201_131.nii.gz</td>\n",
       "      <td>118_6010016870769_0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42820</th>\n",
       "      <td>118</td>\n",
       "      <td>6010018198758.0</td>\n",
       "      <td>201</td>\n",
       "      <td>148</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>062Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips</td>\n",
       "      <td>iCT 256</td>\n",
       "      <td>B</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>[340, 340]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>Neck-Pelivis /iCT in HU</td>\n",
       "      <td>6010018198876.0</td>\n",
       "      <td>118_6010018198758_0201_148.nii.gz</td>\n",
       "      <td>118_6010018198758_0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42821</th>\n",
       "      <td>118</td>\n",
       "      <td>6010018748732.0</td>\n",
       "      <td>301</td>\n",
       "      <td>164</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>076Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips</td>\n",
       "      <td>iCT 256</td>\n",
       "      <td>B</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>[300, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>Neck-Pelivis /iCT in HU</td>\n",
       "      <td>6010018748850.0</td>\n",
       "      <td>118_6010018748732_0301_164.nii.gz</td>\n",
       "      <td>118_6010018748732_0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42822</th>\n",
       "      <td>118</td>\n",
       "      <td>6010018776642.0</td>\n",
       "      <td>201</td>\n",
       "      <td>170</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>082Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips</td>\n",
       "      <td>iCT 256</td>\n",
       "      <td>B</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>[340, 340]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>Neck-Pelivis /iCT in HU</td>\n",
       "      <td>6010018776760.0</td>\n",
       "      <td>118_6010018776642_0201_170.nii.gz</td>\n",
       "      <td>118_6010018776642_0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42823</th>\n",
       "      <td>118</td>\n",
       "      <td>6010018780460.0</td>\n",
       "      <td>201</td>\n",
       "      <td>158</td>\n",
       "      <td>CT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>075Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips</td>\n",
       "      <td>iCT 256</td>\n",
       "      <td>B</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>[320, 320]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ORIGINAL', 'PRIMARY', 'AXIAL']</td>\n",
       "      <td>Neck-Pelivis /iCT in HU</td>\n",
       "      <td>6010018780578.0</td>\n",
       "      <td>118_6010018780460_0201_158.nii.gz</td>\n",
       "      <td>118_6010018780460_0201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42824 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Facility_Code     Accesion_Number  Series_Number  Number_of_Slices  \\\n",
       "0       43157400144  1148655720201211.0            2.0                53   \n",
       "1       43157400144  1148655720201211.0            3.0                53   \n",
       "2       43157400144  1148655720201211.0            4.0                53   \n",
       "3       43157400144  1148655720201211.0            5.0                53   \n",
       "4       43157400144  1167702520201223.0            2.0               131   \n",
       "...             ...                 ...            ...               ...   \n",
       "42819           118     6010016870769.0            201               131   \n",
       "42820           118     6010018198758.0            201               148   \n",
       "42821           118     6010018748732.0            301               164   \n",
       "42822           118     6010018776642.0            201               170   \n",
       "42823           118     6010018780460.0            201               158   \n",
       "\n",
       "       modality  slice_thickness  patient_sex  patient_age  \\\n",
       "0            CT              5.0            M         074Y   \n",
       "1            CT              5.0            M         074Y   \n",
       "2            CT              5.0            M         074Y   \n",
       "3            CT              5.0            M         074Y   \n",
       "4            CT              5.0            F         072Y   \n",
       "...         ...              ...          ...          ...   \n",
       "42819        CT              5.0            F         034Y   \n",
       "42820        CT              5.0            F         062Y   \n",
       "42821        CT              5.0            M         076Y   \n",
       "42822        CT              5.0            M         082Y   \n",
       "42823        CT              5.0            F         075Y   \n",
       "\n",
       "       contrast_bolus_agent        manufacturer          model_name  \\\n",
       "0                       NaN  GE MEDICAL SYSTEMS  Discovery CT750 HD   \n",
       "1                       NaN  GE MEDICAL SYSTEMS  Discovery CT750 HD   \n",
       "2                       NaN  GE MEDICAL SYSTEMS  Discovery CT750 HD   \n",
       "3                       NaN  GE MEDICAL SYSTEMS  Discovery CT750 HD   \n",
       "4                       NaN  GE MEDICAL SYSTEMS  Discovery CT750 HD   \n",
       "...                     ...                 ...                 ...   \n",
       "42819                   NaN             Philips             iCT 256   \n",
       "42820                   NaN             Philips             iCT 256   \n",
       "42821                   NaN             Philips             iCT 256   \n",
       "42822                   NaN             Philips             iCT 256   \n",
       "42823                   NaN             Philips             iCT 256   \n",
       "\n",
       "       conv_kernel  window_center  window_width  patient_orientation  \\\n",
       "0         STANDARD             35           300                  NaN   \n",
       "1         STANDARD             55           320                  NaN   \n",
       "2         STANDARD             55           320                  NaN   \n",
       "3         STANDARD             55           320                  NaN   \n",
       "4         STANDARD             30           300                  NaN   \n",
       "...            ...            ...           ...                  ...   \n",
       "42819            B       [40, 40]    [340, 340]                  NaN   \n",
       "42820            B       [40, 40]    [340, 340]                  NaN   \n",
       "42821            B       [40, 40]    [300, 300]                  NaN   \n",
       "42822            B       [40, 40]    [340, 340]                  NaN   \n",
       "42823            B       [40, 40]    [320, 320]                  NaN   \n",
       "\n",
       "                             image_type  \\\n",
       "0      ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "1      ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "2      ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "3      ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "4      ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "...                                 ...   \n",
       "42819  ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "42820  ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "42821  ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "42822  ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "42823  ['ORIGINAL', 'PRIMARY', 'AXIAL']   \n",
       "\n",
       "                                 protocol_name                  ID  \\\n",
       "0      6.9 ThorAbd Liver Dynamic 3phase+Thorax  1148698877601355.0   \n",
       "1      6.9 ThorAbd Liver Dynamic 3phase+Thorax  1148698877601355.0   \n",
       "2      6.9 ThorAbd Liver Dynamic 3phase+Thorax  1148698877601355.0   \n",
       "3      6.9 ThorAbd Liver Dynamic 3phase+Thorax  1148698877601355.0   \n",
       "4                               5.10 ThorPel P  1167745677601367.0   \n",
       "...                                        ...                 ...   \n",
       "42819                 Chest-Pelivis /iCT in HU     6010016870887.0   \n",
       "42820                  Neck-Pelivis /iCT in HU     6010018198876.0   \n",
       "42821                  Neck-Pelivis /iCT in HU     6010018748850.0   \n",
       "42822                  Neck-Pelivis /iCT in HU     6010018776760.0   \n",
       "42823                  Neck-Pelivis /iCT in HU     6010018780578.0   \n",
       "\n",
       "                                               path  \\\n",
       "0      43157400144_1148655720201211_0002_053.nii.gz   \n",
       "1      43157400144_1148655720201211_0003_053.nii.gz   \n",
       "2      43157400144_1148655720201211_0004_053.nii.gz   \n",
       "3      43157400144_1148655720201211_0005_053.nii.gz   \n",
       "4      43157400144_1167702520201223_0002_131.nii.gz   \n",
       "...                                             ...   \n",
       "42819             118_6010016870769_0201_131.nii.gz   \n",
       "42820             118_6010018198758_0201_148.nii.gz   \n",
       "42821             118_6010018748732_0301_164.nii.gz   \n",
       "42822             118_6010018776642_0201_170.nii.gz   \n",
       "42823             118_6010018780460_0201_158.nii.gz   \n",
       "\n",
       "                                   path_  \n",
       "0      43157400144_1148655720201211_0002  \n",
       "1      43157400144_1148655720201211_0003  \n",
       "2      43157400144_1148655720201211_0004  \n",
       "3      43157400144_1148655720201211_0005  \n",
       "4      43157400144_1167702520201223_0002  \n",
       "...                                  ...  \n",
       "42819             118_6010016870769_0201  \n",
       "42820             118_6010018198758_0201  \n",
       "42821             118_6010018748732_0301  \n",
       "42822             118_6010018776642_0201  \n",
       "42823             118_6010018780460_0201  \n",
       "\n",
       "[42824 rows x 20 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 19)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df[' Number_of_Slices']>450].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_dir = '../data/finish_pred/'\n",
    "finished_list = []\n",
    "finished_paths = sorted(glob.glob(os.path.join(data_dir,'*.nii.gz')))\n",
    "for path in finished_paths:\n",
    "    img_path = path.split('.')[0]+'_0000.nii.gz'\n",
    "    finished_list.append(img_path)\n",
    "\n",
    "pd.DataFrame(finished_list).T.to_csv('finished.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.0.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.11.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 170093375ce29267e45681fcec09dfa856e1d7e7\n",
      "MONAI __file__: /home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.12.0\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.4.2\n",
      "einops version: 0.4.1\n",
      "transformers version: 4.14.1\n",
      "mlflow version: 1.25.1\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "from torch.utils.data import default_collate\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, ImageDataset, PersistentDataset, pad_list_data_collate, ThreadBuffer\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    RandRotate90,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n",
    "from monai.utils import get_torch_version_tuple, set_determinism\n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../data/abd_20220101-20220605/118_*.nii.gz')[:20]\n",
    "# 2 binary labels for gender classification: man or woman\n",
    "labels = np.array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "# Represent labels in one-hot format for binary classifier training,\n",
    "# BCEWithLogitsLoss requires target to have same shape as input\n",
    "labels = torch.nn.functional.one_hot(torch.as_tensor(labels)).float()\n",
    "\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(images, labels)\n",
    "]\n",
    "\n",
    "amp = True\n",
    "use_buffer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'monai.data.meta_tensor.MetaTensor'> (1, 1, 512, 512, 154) tensor([[1., 0.]]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "##cacheする場所を設定する\n",
    "\n",
    "persistent_cache = pathlib.Path(os.getcwd(), \"persistent_cache\")\n",
    "persistent_cache.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize((96, 96, 96)) ])\n",
    "\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-57,\n",
    "                a_max=164,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "val_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize((96, 96, 96))])\n",
    "\n",
    "#data = default_collate([images,labels])\n",
    "\n",
    "# Define nifti dataset, data loader\n",
    "check_ds = PersistentDataset(\n",
    "    data=data_dicts[:10], transform=train_transforms, cache_dir=persistent_cache\n",
    ")\n",
    "check_loader = DataLoader(check_ds, batch_size=1, num_workers=2, pin_memory=pin_memory,collate_fn=pad_list_data_collate,)\n",
    "\n",
    "batch= monai.utils.misc.first(check_loader)\n",
    "im,label = batch['image'],batch['label']\n",
    "print(type(im), im.shape, label, label.shape)\n",
    "\n",
    "# create a training data loader\n",
    "\n",
    "train_ds = PersistentDataset(\n",
    "    data=data_dicts[:10], transform=train_transforms, cache_dir=persistent_cache\n",
    ")\n",
    "#train_ds = ImageDataset(image_files=images[:10], labels=labels[:10], transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=pin_memory, collate_fn=pad_list_data_collate,)\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = PersistentDataset(\n",
    "    data=data_dicts[:-10], transform=val_transforms, cache_dir=persistent_cache\n",
    ")\n",
    "#val_ds = ImageDataset(image_files=images[-10:], labels=labels[-10:], transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=pin_memory, collate_fn=pad_list_data_collate,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 512, 512, 154)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(check_loader))['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/5\n",
      "1/5, train_loss: 0.6777 step time: 0.7180\n",
      "2/5, train_loss: 0.5593 step time: 1.3357\n",
      "3/5, train_loss: 0.5142 step time: 1.1398\n",
      "4/5, train_loss: 0.7891 step time: 0.5784\n",
      "5/5, train_loss: 0.9563 step time: 1.2021\n",
      "epoch 1 average loss: 0.6993\n",
      "----------\n",
      "epoch 2/5\n",
      "1/5, train_loss: 0.4247 step time: 1.0870\n",
      "2/5, train_loss: 0.6340 step time: 0.8471\n",
      "3/5, train_loss: 0.6943 step time: 0.5727\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 688.00 MiB (GPU 0; 23.70 GiB total capacity; 15.55 GiB already allocated; 129.31 MiB free; 21.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/hdd/jmid/download_from_server/code/eda.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/hdd/jmid/download_from_server/code/eda.ipynb#ch0000034?line=34'>35</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/hdd/jmid/download_from_server/code/eda.ipynb#ch0000034?line=35'>36</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/hdd/jmid/download_from_server/code/eda.ipynb#ch0000034?line=36'>37</a>\u001b[0m scaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/hdd/jmid/download_from_server/code/eda.ipynb#ch0000034?line=37'>38</a>\u001b[0m scaler\u001b[39m.\u001b[39mstep(optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/hdd/jmid/download_from_server/code/eda.ipynb#ch0000034?line=38'>39</a>\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py:355\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=307'>308</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=308'>309</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=309'>310</a>\u001b[0m \u001b[39mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=351'>352</a>\u001b[0m \u001b[39m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=352'>353</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39;49mbackward,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39;49m,),\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=357'>358</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=358'>359</a>\u001b[0m         gradient\u001b[39m=\u001b[39;49mgradient,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=359'>360</a>\u001b[0m         retain_graph\u001b[39m=\u001b[39;49mretain_graph,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39;49mcreate_graph,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs)\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py:1394\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1387'>1388</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1388'>1389</a>\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mwill be an error in PyTorch 1.11, please define it as a classmethod.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1389'>1390</a>\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1391'>1392</a>\u001b[0m \u001b[39m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1392'>1393</a>\u001b[0m \u001b[39m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1393'>1394</a>\u001b[0m result \u001b[39m=\u001b[39m torch_func_method(public_api, types, args, kwargs)\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1395'>1396</a>\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/overrides.py?line=1396'>1397</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py:249\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=246'>247</a>\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=247'>248</a>\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=248'>249</a>\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, kwargs)\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=249'>250</a>\u001b[0m \u001b[39m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=250'>251</a>\u001b[0m \u001b[39m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=251'>252</a>\u001b[0m \u001b[39m#     return ret\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=252'>253</a>\u001b[0m \u001b[39m# we might have 1 or multiple outputs. Might be MetaTensor, might be something\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=253'>254</a>\u001b[0m \u001b[39m# else (e.g., `__repr__` returns a string).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=254'>255</a>\u001b[0m \u001b[39m# Convert to list (if necessary), process, and at end remove list if one was added.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=255'>256</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=256'>257</a>\u001b[0m     \u001b[39mhasattr\u001b[39m(torch, \u001b[39m\"\u001b[39m\u001b[39mreturn_types\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=257'>258</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=261'>262</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/meta_tensor.py?line=262'>263</a>\u001b[0m     \u001b[39m# for torch.max(torch.tensor(1.0), dim=0), the return type is named-tuple like\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py:1142\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=1138'>1139</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=1140'>1141</a>\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=1141'>1142</a>\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=1142'>1143</a>\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=1143'>1144</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 688.00 MiB (GPU 0; 23.70 GiB total capacity; 15.55 GiB already allocated; 129.31 MiB free; 21.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "scaler = torch.cuda.amp.GradScaler() if amp else None\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "writer = SummaryWriter()\n",
    "max_epochs = 5\n",
    "set_determinism(seed=0)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    src = ThreadBuffer(train_loader, 1) if use_buffer else train_loader\n",
    "    for batch_data in src:\n",
    "        step_start = time.time()\n",
    "        step += 1\n",
    "        inputs, labels = batch_data['image'].to(device), batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if amp and scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "                f\"{step}/{len(train_ds) // train_loader.batch_size},\"\n",
    "                f\" train_loss: {loss.item():.4f}\"\n",
    "                f\" step time: {(time.time() - step_start):.4f}\"\n",
    "        )\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "\n",
    "        # outputs = model(inputs)\n",
    "        # loss = loss_function(outputs, labels)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # epoch_loss += loss.item()\n",
    "        # epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "\n",
    "        num_correct = 0.0\n",
    "        metric_count = 0\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data['image'].to(device), val_data['label'].to(device)\n",
    "            if amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels.argmax(dim=1))\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels.argmax(dim=1))\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                    \n",
    "        metric = num_correct / metric_count\n",
    "        metric_values.append(metric)\n",
    "\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), \"best_metric_model_classification3d_array.pth\")\n",
    "            print(\"saved new best metric model\")\n",
    "\n",
    "        print(f\"Current epoch: {epoch+1} current accuracy: {metric:.4f} \")\n",
    "        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n",
    "\n",
    "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 90, in apply_transform\n    return [_apply_transform(transform, item, unpack_items) for item in data]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 90, in <listcomp>\n    return [_apply_transform(transform, item, unpack_items) for item in data]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 55, in _apply_transform\n    return transform(parameters)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/intensity/array.py\", line 455, in __call__\n    ret = rescale_array(img_t, self.minv, self.maxv, dtype=self.dtype)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/utils.py\", line 184, in rescale_array\n    arr, *_ = convert_data_type(arr, dtype=dtype)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/utils/type_conversion.py\", line 307, in convert_data_type\n    raise ValueError(f\"Unsupported output type: {output_type}\")\nValueError: Unsupported output type: <class 'str'>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 105, in __getitem__\n    return self._transform(index)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 408, in _transform\n    pre_random_item = self._cachecheck(self.data[index])\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 381, in _cachecheck\n    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 320, in _pre_transform\n    item_transformed = apply_transform(_xform, item_transformed)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 118, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.intensity.array.ScaleIntensity object at 0x7fbf50694cd0>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/hdd/jmid/download_from_server/code/eda.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/hdd/jmid/download_from_server/code/eda.ipynb#ch0000036?line=0'>1</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1221'>1222</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1222'>1223</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1223'>1224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1247'>1248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1248'>1249</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1249'>1250</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1250'>1251</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_utils.py?line=452'>453</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_utils.py?line=453'>454</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_utils.py?line=454'>455</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_utils.py?line=455'>456</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/_utils.py?line=456'>457</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 90, in apply_transform\n    return [_apply_transform(transform, item, unpack_items) for item in data]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 90, in <listcomp>\n    return [_apply_transform(transform, item, unpack_items) for item in data]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 55, in _apply_transform\n    return transform(parameters)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/intensity/array.py\", line 455, in __call__\n    ret = rescale_array(img_t, self.minv, self.maxv, dtype=self.dtype)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/utils.py\", line 184, in rescale_array\n    arr, *_ = convert_data_type(arr, dtype=dtype)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/utils/type_conversion.py\", line 307, in convert_data_type\n    raise ValueError(f\"Unsupported output type: {output_type}\")\nValueError: Unsupported output type: <class 'str'>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 105, in __getitem__\n    return self._transform(index)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 408, in _transform\n    pre_random_item = self._cachecheck(self.data[index])\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 381, in _cachecheck\n    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/data/dataset.py\", line 320, in _pre_transform\n    item_transformed = apply_transform(_xform, item_transformed)\n  File \"/home/jubuntu/anaconda3/envs/monai/lib/python3.8/site-packages/monai/transforms/transform.py\", line 118, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.intensity.array.ScaleIntensity object at 0x7fbf50694cd0>\n"
     ]
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb4d34cff383dc67a77588733b6199e6d2b48903625f73b314bf5a584ef02ba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
